from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain_chroma import Chroma

from typing import List
import os
import streamlit as st
from streamlit_chatbox import *
import time
import textwrap
from RAG.selfqueryingretriever_contents import SelfQueryingRetrieverContents
from RAG.selfqueryingretriever_title import SelfQueryingRetrieverTitle

from recommendation.item_base_rec import get_recommendations_for_item

MODEL = "gpt-4o-mini"
SUB_MODEL = "gpt-3.5-turbo"


# 1. ì˜ë„ë¶„ë¥˜
class Search(BaseModel):
    """ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜ëœ ê²°ê³¼ë¥¼ ë°˜í™˜ -> ì—¬í–‰ì§€ì¶”ì²œ, ê¸°íƒ€"""

    questionType: str = Field(
        ...,
        description="ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì—¬í–‰ì§€ì¶”ì²œ, ê¸°íƒ€ ì¤‘ í•˜ë‚˜ë¡œ ë°˜í™˜",
    )
    keywords: List[str] = Field(None, description="í•µì‹¬ í‚¤ì›Œë“œ")
    place_category: str = Field (None, description="'ì¥ì†Œë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œì˜ ì§ˆë¬¸','íŠ¹ì • ì¥ì†Œì— ê´€í•œ ì§ˆë¬¸' ì¤‘ í•˜ë‚˜ë¥¼ ë°˜í™˜")
    

class Document:
    def __init__(self, page_content, metadata):
        self.page_content = page_content
        self.metadata = metadata


def main():
    with open("./JW_openai_credential_gpt35.txt", 'r') as f:
        api_key = f.read()
    os.environ["OPENAI_API_KEY"] = api_key

    system = """
        ë‹¹ì‹ ì€ ì§ˆë¬¸ì˜ ì˜ë„ íŒŒì•… ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.

        ## ì§€ì‹œì‚¬í•­ :
        - ë‹¹ì‹ ì€ ì£¼ì–´ì§€ëŠ” ì§ˆë¬¸ì˜ ìœ í˜•ì„ 'ì—¬í–‰ì§€ì¶”ì²œ', 'ê¸°íƒ€' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•œ ê²°ê³¼ë¥¼ questionTypeìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹ì • ì—¬í–‰ì§€ ì´í›„ ë°©ë¬¸í•  ê³³ì´ë‚˜, íŠ¹ì • ì—¬í–‰ì§€ì™€ ìœ ì‚¬í•œ ê³³ì„ ë¬¼ì–´ë³¼ ê²½ìš° 'ì—¬í–‰ì§€ì¶”ì²œ'ì„ ë„£ê³ , ë§Œì•½ ì–´ë–¤ ì¥ì†Œì— ê´€ë ¨ëœ ì„¤ëª…ì´ë‚˜ íƒœê·¸ë¥¼ ë¬¼ì–´ë³´ëŠ” ë“± ê¸°íƒ€ ì§ˆë¬¸ì„ í•  ê²½ìš° 'ê¸°íƒ€'ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
        - ì§ˆë¬¸ ì†ì— ì¥ì†Œê°€ ëª…ì‹œëœ ìœ ë¬´ì— ë”°ë¼ place_categoryë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤. ì´ë•Œ'ì„±ì‚°ì¼ì¶œë´‰'ê³¼ ê°™ì´ ì—¬í–‰ì§€/ìˆ™ë°•ì—…ì†Œ/ë§›ì§‘ì˜ ì´ë¦„ì´ ì •í™•í•˜ê²Œ ë“±ì¥í•˜ëŠ” ê²½ìš° '1', ì—†ëŠ” ê²½ìš°ì—ëŠ” '2'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ë„£ìœ¼ì„¸ìš”.
        - ì§ˆë¬¸ ì†ì—ì„œ ë“±ì¥í•œ ì¥ì†Œë“¤ì„ í•µì‹¬ í‚¤ì›Œë“œë¡œ ì¶”ì¶œí•˜ì—¬ keywordsì— ë„£ìœ¼ì„¸ìš”.

            --
        ## ì˜ˆì‹œ 1. 
        ì…ë ¥ë°›ì€ ì§ˆë¬¸ì´ "ìš°ë„ì—ì„œ ê°ˆë§Œí•œ ì¹´í˜ ì•Œë ¤ì¤˜" ë¼ë©´
        "questionType": "ê¸°íƒ€","keywords": ["ìš°ë„", "ì¹´í˜"],"place_category": "2" ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        ## ì˜ˆì‹œ 2. 
        ì…ë ¥ë°›ì€ ì§ˆë¬¸ì´ "ì¤‘ë¬¸ì—ì„œ ë§›ìˆëŠ” ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘ ì¶”ì²œí•´ì¤„ ìˆ˜ ìˆë‚˜ìš”?" ë¼ë©´
        "questionType": "ê¸°íƒ€","keywords": ["ì¤‘ë¬¸", "ì´íƒˆë¦¬ì•ˆ ë ˆìŠ¤í† ë‘"],"place_category": "2" ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        ## ì˜ˆì‹œ 3. 
        ì…ë ¥ë°›ì€ ì§ˆë¬¸ì´ "ì„±ì‚°ì¼ì¶œë´‰ ë‹¤ìŒìœ¼ë¡œ ê°ˆë§Œí•œ ê³³ì„ ì•Œë ¤ì¤˜" ë¼ë©´
        "questionType": "ì—¬í–‰ì§€ì¶”ì²œ","keywords": ["ì„±ì‚°ì¼ì¶œë´‰"],"place_category": "1" ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        ## ì£¼ì˜ì‚¬í•­!
            - ì§ˆë¬¸ ì†ì— ì¥ì†Œê°€ ëª…ì‹œëœ ìœ ë¬´ì— ë”°ë¼ place_categoryë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤. ì´ë•Œ'ì„±ì‚°ì¼ì¶œë´‰'ê³¼ ê°™ì´ ì—¬í–‰ì§€/ìˆ™ë°•ì—…ì†Œ/ë§›ì§‘ì˜ ì´ë¦„ì´ ë“±ì¥í•˜ëŠ” ê²½ìš° '1', ì—†ëŠ” ê²½ìš°ì—ëŠ” '2'ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ë„£ìœ¼ì„¸ìš”.
    """

    prompt = ChatPromptTemplate.from_messages([
            ("system", textwrap.dedent(system)),
            ("human", "{question}"),
        ]
    )

    llm = ChatOpenAI(model=MODEL, temperature=0)


    structured_llm = llm.with_structured_output(Search)
    query_analyzer = {"question": RunnablePassthrough()} | prompt | structured_llm

######
#2. ê¸°ë³¸ë‹µë³€
    basicprompt = ChatPromptTemplate.from_messages(
        [
            ("system", '''ë‹¹ì‹ ì€ ì œì£¼ë„ë¡œ ì—¬í–‰ ì˜¨ ì‚¬ëŒë“¤ì„ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•˜ê³  ê·€ì—¬ìš´ ì¶”ì²œëƒ¥ğŸ˜½ì…ë‹ˆë‹¤. 
                        ì¶”ì²œê²°ê³¼ë¥¼ ì„¤ëª… í•  ë•Œ ê°€ë”ì”© ë¬¸ì¥ê³¼ ì–´ìš¸ë¦¬ëŠ” ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•´ì„œ ëŒ€ë‹µí•˜ì„¸ìš”. 
                        ë§ ëì— ê³ ì–‘ì´ì²˜ëŸ¼ "ëƒ¥" ì„ ë„£ê±°ë‚˜ ê³ ì–‘ì´ ì´ëª¨í‹°ì½˜ì„ í™œìš©í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ë©´ "í–ˆë‹¤ëƒ¥ğŸ’–ğŸ±"           
                        ë§Œì•½ ì£¼ì–´ì§„ ì§ˆë¬¸ì´ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ë¬»ëŠ” ì§ˆë¬¸ì´ë©´ ë‚˜ëŠ” ê·€ì—¬ìš´ ê³ ì–‘ì´ë¼ì„œ ì´ ë‚´ìš©ì€ ì˜ ëª¨ë¥´ë‹ˆ ì§ˆë¬¸ì„ ë°”ê¿”ì„œ í•´ ë‹¬ë¼ê³  ìš”ì²­í•˜ì„¸ìš”.
                    '''),
            ("human", "{question}"),
        ]
    )
    basicllm = ChatOpenAI(model=MODEL, temperature=0.5)
    chain = {"question": RunnablePassthrough()} | basicprompt | basicllm | StrOutputParser()


######
#ì¶”ì²œê²°ê³¼ ë‹µë³€ í”„ë¡¬í”„íŠ¸
    system_prompt = """ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì¶”ì²œ ê²°ê³¼ë¥¼ ì„¤ëª…í•´ì£¼ëŠ” ì¹œì ˆí•˜ê³  ê·€ì—¬ìš´ ì¶”ì²œëƒ¥ğŸ˜½ì…ë‹ˆë‹¤. 
        ## ì§€ì‹œì‚¬í•­ :
        - ì£¼ì–´ì§„ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•´ì£¼ì„¸ìš”.
        - ë§ ëì— ê³ ì–‘ì´ì²˜ëŸ¼ 'ëƒ¥' ì„ ë„£ê±°ë‚˜ ê³ ì–‘ì´ ì´ëª¨í‹°ì½˜ì„ í™œìš©í•˜ì„¸ìš”.
        - ë‹µë³€ ì‹œ ë•Œë•Œë¡œ ë¬¸ì¥ì— ì–´ìš¸ë¦¬ëŠ” ì´ëª¨í‹°ì½˜ì„ í™œìš©í•˜ì„¸ìš”.""" #ì •í™•í•œ ìœ„ì¹˜ì™€ ì •í™•í•œ ìµœì‹  ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤ë©´ ì´ë¥¼ í•¨ê»˜ ì¶œë ¥í•˜ì„¸ìš” ë˜í•œ ë„¤ì´ë²„ ì§€ë„ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ë·°ê°€ ë§ì€ ì¹´í˜ê°€ ìˆë‹¤ë©´ ì •í™•í•œ ë©”ë‰´, ê°€ê²©ë“±ì„ í•¨ê»˜ ì†Œê°œí•´ì£¼ì„¸ìš”.
    recprompt = ChatPromptTemplate.from_messages(
        [
            ("system", textwrap.dedent(system_prompt)),
            ("human", "{question}"),
        ]
    )
    recllm = ChatOpenAI(model=MODEL, temperature=0.51)
    rec_chain = {"question": RunnablePassthrough()} | recprompt | recllm



####
# RAG for ë™ì„  ì¶”ì²œ
# VectorStore ë° ê²€ìƒ‰ê¸° ì„¤ì •
    vectorstore = Chroma(persist_directory="./vectorstores/wifilist_lat_db_v2", embedding_function=OpenAIEmbeddings(),
                         create_collection_if_not_exists=False)
    retriever = vectorstore.as_retriever(k=1)

# ë¬¸ì„œ í˜•ì‹ ì§€ì •
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)


    recragtemplate = """
        ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¬êµ¬ì„±í•´ Userì—ê²Œ ì í•©í•œ ë™ì„ ê³¼ ê±°ë¦¬ë¥¼ ì¶”ì²œí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. wifilist_lat_db_v2 Vector Storeë¥¼ ì˜ ì°¸ê³ í•´ì„œ, apGroupNameì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë‚´ìš©ë§Œì„ ë¬¸ì„œë¡œ ë½‘ìœ¼ì„¸ìš”. Vector Store ì† ì •í™•í•œ latitudeì™€ longitudeë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”. ëª¨ë“  ê°€ëŠ¥í•œ ì¡°í•©ì—ì„œ, latitudeì™€ longitude ì°¨ì´ì˜ ì ˆëŒ€ê°’ì˜ í•©, ì¦‰ ë§¨í•˜íƒ„ ê±°ë¦¬ê°€ ê°€ì¥ ì§§ì€ ê²ƒë¶€í„° ë™ì„ ì„ ì„ íƒí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

    ### ì˜ˆì‹œ 1:
    Question: ë‚˜ëŠ” ì œì£¼ë„ì—ì„œ ì—¬í–‰ì¤‘ì´ì•¼. ì¶œë°œì§€ëŠ” 'ì²œì§€ì—°í­í¬'ì´ê³ , ì´í›„ ë‚´ê°€ ë°©ë¬¸í•  ê³³ì€ 'ì„¸í™” í•´ë³€', 'í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥)', 'ì œì£¼ì„œë¬¸ì‹œì¥' ì´ì•¼. ì œì¼ ê°€ê¹Œìš´ ê³³ë¶€í„° ê°€ë ¤ê³  í•˜ëŠ”ë°, ìµœì ì˜ ë™ì„ ì„ ì¶œë ¥í•´ì¤˜!
    Context: {context}


    [ì‚¬ê³ ê³¼ì •]
    wifilist_lat_db_v2ë¼ëŠ” vector storeì—ì„œ, ì¶œë°œì§€ 'ì²œì§€ì—°í­í¬'ì˜ latitudeëŠ” 33.246139ì´ê³  longitudeëŠ” 126.55595ì´ë‹¤. 
    ë°©ë¬¸í•  ì¥ì†ŒëŠ” 'ì„¸í™” í•´ë³€', 'í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥)', 'ì œì£¼ì„œë¬¸ì‹œì¥' ì´ë‹¤.
    ë°©ë¬¸í•  ì¥ì†Œë“¤ì˜ latitude, longitudeë¥¼ ê°ê° wifilist_lat_db_v2ì—ì„œ ì°¾ì•„ë³¸ë‹¤. 'ì„¸í™” í•´ë³€' (latitude: 33.525276, longitude:126.859629), "í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥)" (latitude: 33.39476, longitude: 126.241228), "ì œì£¼ì„œë¬¸ì‹œì¥" (latitude: 33.511121,longitude:126.51778)ì´ê³ 
    'ì²œì§€ì—°í­í¬'ì™€ ê°€ì¥ ê°€ê¹Œìš´ ê³³ì„ ì°¾ê¸° ìœ„í•´ ì²œì§€ì—° í­í¬ì™€ ë°©ë¬¸í•  ì¥ì†Œë“¤ì˜ latitude, longitude ì°¨ì´ì˜ í•©ì„ êµ¬í•œë‹¤. 

    'ì²œì§€ì—°í­í¬'ë¡œë¶€í„° ë°©ë¬¸í•  ì¥ì†Œë“¤ê¹Œì§€ì˜ latitude, longitude ì°¨ì´:
    1. ì„¸í™” í•´ë³€ (33.246139 - 33.525276, 126.55595 - 126.859629) -> ë§¨í•´íŠ¼ ê±°ë¦¬: -(-0.263886) + (-(-0.303679)) = 0.567565
    2. í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥) (33.246139 - 33.39476, 126.55595 - 126.241228) -> ë§¨í•´íŠ¼ ê±°ë¦¬: -(-0.148621) + 0.314722 = 0.463343
    3. ì œì£¼ì„œë¬¸ì‹œì¥ (33.246139 - 33.511121, 126.55595 - 126.51778) -> ë§¨í•´íŠ¼ ê±°ë¦¬: -(-0.264982) + 0.03817 = 0.303152

    ë”°ë¼ì„œ ì²˜ìŒìœ¼ë¡œ ë°©ë¬¸í•  ê³³ì€ ë§¨í•´íŠ¼ê±°ë¦¬ê°€ 0.303152ë¡œ ê°€ì¥ ì§§ì€ 'ì œì£¼ì„œë¬¸ì‹œì¥'ì´ë‹¤. ë‹¤ìŒì€ 'ì œì£¼ì„œë¬¸ì‹œì¥'ì—ì„œë¶€í„°, ë°©ë¬¸í•  ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ì† ì•„ì§ ë°©ë¬¸í•˜ì§€ ì•Šì€ ì›ì†Œì¸ 'ì„¸í™” í•´ë³€', 'í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥)'ê¹Œì§€ì˜ ë§¨í•´íŠ¼ ê±°ë¦¬ë¥¼ êµ¬í•œë‹¤.

    "ì œì£¼ì„œë¬¸ì‹œì¥"ë¶€í„° ë¦¬ìŠ¤íŠ¸ì† ì›ì†Œê¹Œì§€ì˜ latitude, longitude ì°¨ì´:
    1. ì„¸í™” í•´ë³€ (33.511121 - 33.525276, 126.51778 - 126.859629) -> ë§¨í•´íŠ¼ ê±°ë¦¬: -(-0.014155) + -(-0.341849) = 0.356004
    2. í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥) (33.511121- 33.39476, 126.51778 - 126.241228) -> ë§¨í•´íŠ¼ ê±°ë¦¬: 0.11635 + 0.276552 = 0.392902

    ë”°ë¼ì„œ 'ì œì£¼ì„œë¬¸ì‹œì¥' ë‹¤ìŒìœ¼ë¡œ ë°©ë¬¸í•  ê³³ì€ ë‘˜ ì¤‘ ë§¨í•´íŠ¼ ê±°ë¦¬ê°€ ë” ì§§ì€ 'ì„¸í™” í•´ë³€' ì´ë‹¤.
    ë§ˆì§€ë§‰ìœ¼ë¡œëŠ” ë‚¨ì•„ìˆëŠ” ì›ì†Œì¸ 'í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥)'ë¥¼ ë°©ë¬¸í•œë‹¤.

    :Answer:
    ì²œì§€ì—°í­í¬ ë‹¤ìŒìœ¼ë¡œ ìµœë‹¨ê±°ë¦¬ ë™ì„ ì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš” ;) ì œì£¼ì„œë¬¸ì‹œì¥ -> ì„¸í™”í•´ë³€ -> í˜‘ì¬ í•´ë³€(í˜‘ì¬í•´ìˆ˜ìš•ì¥) ìˆœì„œë¡œ ë°©ë¬¸í•˜ì„¸ìš”ëƒ¥!



### ìƒˆë¡œìš´ ì§ˆë¬¸:
    Question: {question}
    Context: {context}

    Answer: 

    """

    recragprompt = ChatPromptTemplate.from_template(textwrap.dedent(recragtemplate))

    rec_rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | recragprompt
        | llm
        | StrOutputParser()
    )

####### í˜ì´ì§€ ëœë”©

    st.title('ì œì£¼ëƒ¥ğŸ˜½')
    init_content = "ë°˜ê°€ì›Œ!ğŸ±ğŸ’ ë‚˜ëŠ” ì œì£¼ë„ì— ê´€í•œ ë‹µë³€ì„ í•´ì£¼ëŠ” ì œì£¼ëƒ¥ì´ë‹¤ëƒ¥! ì œì£¼ë„ ë§›ì§‘ì´ë‚˜ ì¹´í˜, ì—¬í–‰ì§€, ìˆ™ë°•ì—…ì†Œ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ ì£¼ë©´ ì´ ëª¸ì´ ì¹œì ˆí•˜ê²Œ ì•Œë ¤ì£¼ê² ë‹¤ëƒ¥ (=^ï½¥ï½ªï½¥^=))ï¾‰å½¡â˜†ğŸŠ"
    output=OutputElement(content = init_content, in_expander=True, title='answer',expanded =True,state= 'complete')
    chat_box = ChatBox(greetings=output)


    with st.sidebar:
        st.subheader('start to chat using streamlit')
        streaming = st.checkbox('streaming', True)
        in_expander = st.checkbox('show messages in expander', True)
        

        st.divider()
        btns = st.container()


        # Clear history button
        if st.button("clear_history"):
            chat_box.init_session(clear=True)
            st.experimental_rerun()

    
        st.markdown(
        """
        <div style='position: fixed; bottom: 0; width: 100%; text-align: center; padding: 10px; font-size: 12px; color: gray;'>
            Contact: emodel@naver.com / hoeen5373@gmail.com
        </div>
        """,
        unsafe_allow_html=True
)
    
    chat_box.init_session()
    chat_box.output_messages()

# RAG ì¸ìŠ¤í„´ìŠ¤ 
    selfqueryingretrieverTitle = SelfQueryingRetrieverTitle(llm, 'vectorstores/visitjeju_db_place_food_shopping_stay')
    selfqueryingretrieverContents = SelfQueryingRetrieverContents(llm, 'vectorstores/visitjeju_db_place_food_shopping_stay')
    
    
    query = st.chat_input('ì œì£¼ ì—¬í–‰ì§€ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ ì£¼ì„¸ìš”.')
    if query :
        chat_box.user_say(query)
        if streaming:
            llm_result = query_analyzer.invoke(query)
            print(llm_result.questionType, llm_result.keywords, llm_result.place_category)
            if llm_result.questionType == "ì—¬í–‰ì§€ì¶”ì²œ":
                try:
                    recommended_items = get_recommendations_for_item(llm_result.keywords[0], 'sim_mat_240517.pkl', 'filtered_data_240517.csv')
                    print("rec")
                    generator = rec_chain.invoke(recommended_items)
                except:
                    # RAG logicìœ¼ë¡œ ë³€ê²½ í•„ìš”
                    if llm_result.place_category == '2':
                        print("rag_ì¥ì†Œë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œì˜ ì§ˆë¬¸")
                        title = selfqueryingretrieverContents.query_analyzer.invoke({"question": query})
                        rag_chain = selfqueryingretrieverContents.create_rag_chain(title.place)
                        # print(rag_chain)
                    else:
                        print("rag_ì¥ì†Œì—ëŒ€í•œì§ˆë¬¸")
                        place = selfqueryingretrieverTitle.query_analyzer.invoke({"question": query})
                        rag_chain = selfqueryingretrieverTitle.create_rag_chain(place.place)
                        if rag_chain is None: #title ëª»ì°¾ìŒ
                            title = selfqueryingretrieverContents.query_analyzer.invoke({"question": query})
                            rag_chain = selfqueryingretrieverContents.create_rag_chain(title.place)
                    if rag_chain is not None:
                        generator = rag_chain.invoke(query)
                        
                    else:
                        generator = chain.invoke(query)
            else:
                if llm_result.place_category == '2': #ì¶”ì²œ ì™¸
                    print("ì •ë³´ê²€ìƒ‰_rag_ì¥ì†Œë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœì—ì„œì˜ ì§ˆë¬¸")
                    title = selfqueryingretrieverContents.query_analyzer.invoke({"question": query})
                    rag_chain = selfqueryingretrieverContents.create_rag_chain(title.place)
                
                else:
                    print("ì •ë³´ê²€ìƒ‰_rag_ì¥ì†Œì—ëŒ€í•œì§ˆë¬¸")
                    place = selfqueryingretrieverTitle.query_analyzer.invoke({"question": query})
                    rag_chain = selfqueryingretrieverTitle.create_rag_chain(place.place)

                if rag_chain is not None:
                    generator = rag_chain.invoke(query)
                else:
                    generator = chain.invoke(query)


            elements = chat_box.ai_say(
                [
                    Markdown("thinking", in_expander=in_expander,
                            expanded=True, title="answer"),

                ]
            )
            time.sleep(1)
            text = ""

            if hasattr(generator, 'content'):
                text = generator.content
            else:
                for docs in generator: 
                    text += docs
                    chat_box.update_msg(text, element_index=0, streaming=True)
            # update the element without focus
            chat_box.update_msg(text, element_index=0, streaming=False, state="complete")
